{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD8QV0w6prNs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# קריאת הקובץ\n",
        "file_path = 'flights_original.csv'  # ודא שהשם של הקובץ נכון\n",
        "data = pd.read_csv(file_path, dtype={'ORIGIN_AIRPORT': str, 'DESTINATION_AIRPORT': str}, low_memory=False)\n",
        "\n",
        "# בדיקת ערכים חסרים בכל העמודות\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Missing values in each column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# הדפסת כמות השורות והעמודות\n",
        "num_rows, num_columns = data.shape\n",
        "print(f\"\\nNumber of rows: {num_rows}\")\n",
        "print(f\"Number of columns: {num_columns}\")\n",
        "\n",
        "# שמירת העמודות הרלוונטיות בלבד\n",
        "columns_to_keep = [\n",
        "    'YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE', 'FLIGHT_NUMBER',\n",
        "    'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
        "    'DEPARTURE_TIME', 'DEPARTURE_DELAY'\n",
        "]\n",
        "data = data[columns_to_keep]\n",
        "\n",
        "# הסרת שורות עם ערכי NaNs בעמודות הנדרשות\n",
        "data_cleaned = data.dropna(subset=columns_to_keep)\n",
        "\n",
        "# שמירת הקובץ החדש\n",
        "cleaned_file_path = 'flights_cleaned.csv'\n",
        "data_cleaned.to_csv(cleaned_file_path, index=False)\n",
        "\n",
        "print(f\"Data cleaned and saved to {cleaned_file_path}\")\n",
        "\n",
        "\n",
        "# קריאת הקובץ\n",
        "file_path = 'flights_cleaned.csv'  # ודא שהשם של הקובץ נכון\n",
        "data = pd.read_csv(file_path, dtype={'ORIGIN_AIRPORT': str, 'DESTINATION_AIRPORT': str}, low_memory=False)\n",
        "\n",
        "# בדיקת ערכים חסרים בכל העמודות\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Missing values in each column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# הדפסת כמות השורות והעמודות\n",
        "num_rows, num_columns = data.shape\n",
        "print(f\"\\nNumber of rows: {num_rows}\")\n",
        "print(f\"Number of columns: {num_columns}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "hypothesisone"
      ],
      "metadata": {
        "id": "0O_k4mhbqfcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# קריאת הקובץ עם טיפול בערכים מעורבים\n",
        "file_path = 'flights_cleaned.csv'  # ודא שהשם של הקובץ נכון\n",
        "data = pd.read_csv(file_path, dtype={'ORIGIN_AIRPORT': str, 'DESTINATION_AIRPORT': str}, low_memory=False)\n",
        "\n",
        "# יצירת גרף מכוון מהנתונים\n",
        "def create_directed_graph(data):\n",
        "    G = nx.DiGraph()\n",
        "    for index, row in data.iterrows():\n",
        "        G.add_edge(row['ORIGIN_AIRPORT'], row['DESTINATION_AIRPORT'])\n",
        "    return G\n",
        "\n",
        "graph = create_directed_graph(data)\n",
        "\n",
        "# חישוב Betweenness Centrality\n",
        "betweenness = nx.betweenness_centrality(graph)\n",
        "\n",
        "# יצירת DataFrame עבור מדדי המרכזיות\n",
        "centrality_df = pd.DataFrame(list(betweenness.items()), columns=['Airport', 'Betweenness_Centrality'])\n",
        "\n",
        "# חישוב עיכובים ממוצעים לכל נמל תעופה\n",
        "delay_data = data.groupby('ORIGIN_AIRPORT')['DEPARTURE_DELAY'].mean().reset_index()\n",
        "delay_data.columns = ['Airport', 'Average_Departure_Delay']\n",
        "\n",
        "# מיזוג הנתונים\n",
        "merged_data = pd.merge(centrality_df, delay_data, on='Airport')\n",
        "\n",
        "# הדפסת התוצאות\n",
        "print(merged_data)\n",
        "\n",
        "# יצירת גרף להשוואת מדדי המרכזיות לעיכובים הממוצעים\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Betweenness_Centrality', y='Average_Departure_Delay', data=merged_data)\n",
        "plt.xlabel('Betweenness Centrality')\n",
        "plt.ylabel('Average Departure Delay')\n",
        "plt.title('Betweenness Centrality vs. Average Departure Delay')\n",
        "plt.show()\n",
        "\n",
        "# חישוב הקורלציה\n",
        "correlation = merged_data['Betweenness_Centrality'].corr(merged_data['Average_Departure_Delay'])\n",
        "print(f'Correlation between Betweenness Centrality and Average Departure Delay: {correlation}')"
      ],
      "metadata": {
        "id": "Wlepa58RqPZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "H2"
      ],
      "metadata": {
        "id": "3KmLvNQYqoAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from networkx.algorithms.community import girvan_newman\n",
        "import community.community_louvain as community_louvain\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "\n",
        "# פונקציה לחלוקת הגרף לקהילות לפי אלגוריתם Girvan-Newman\n",
        "def detect_girvan_newman_communities(graph):\n",
        "    comp = girvan_newman(graph)\n",
        "    return next(comp)\n",
        "\n",
        "# פונקציה לחלוקת הגרף לקהילות לפי אלגוריתם Louvain\n",
        "def detect_louvain_communities(graph):\n",
        "    partition = community_louvain.best_partition(graph)\n",
        "    communities = {}\n",
        "    for node, community in partition.items():\n",
        "        if community not in communities:\n",
        "            communities[community] = []\n",
        "        communities[community].append(node)\n",
        "    return list(communities.values())\n",
        "\n",
        "# יצירת גרפים עבור כל חודש\n",
        "def create_graph(data):\n",
        "    G = nx.Graph()\n",
        "    for index, row in data.iterrows():\n",
        "        G.add_edge(row['ORIGIN_AIRPORT'], row['DESTINATION_AIRPORT'])\n",
        "    return G\n",
        "\n",
        "# קריאת הקובץ\n",
        "file_path = 'flights_cleaned.csv'\n",
        "data = pd.read_csv(file_path, dtype={'ORIGIN_AIRPORT': str, 'DESTINATION_AIRPORT': str}, low_memory=False)\n",
        "\n",
        "data_january = data[data['MONTH'] == 1]\n",
        "data_february = data[data['MONTH'] == 2]\n",
        "data_march = data[data['MONTH'] == 3]\n",
        "\n",
        "graph_january = create_graph(data_january)\n",
        "graph_february = create_graph(data_february)\n",
        "graph_march = create_graph(data_march)\n",
        "\n",
        "# בדיקת מספר הצמתים והקשתות בכל חודש\n",
        "print(f\"January: {graph_january.number_of_nodes()} nodes, {graph_january.number_of_edges()} edges\")\n",
        "print(f\"February: {graph_february.number_of_nodes()} nodes, {graph_february.number_of_edges()} edges\")\n",
        "print(f\"March: {graph_march.number_of_nodes()} nodes, {graph_march.number_of_edges()} edges\")\n",
        "\n",
        "# זיהוי קהילות בכל חודש לפי Girvan-Newman\n",
        "communities_january_gn = detect_girvan_newman_communities(graph_january)\n",
        "communities_february_gn = detect_girvan_newman_communities(graph_february)\n",
        "communities_march_gn = detect_girvan_newman_communities(graph_march)\n",
        "\n",
        "num_communities_january_gn = len(list(communities_january_gn))\n",
        "num_communities_february_gn = len(list(communities_february_gn))\n",
        "num_communities_march_gn = len(list(communities_march_gn))\n",
        "\n",
        "print(f\"Girvan-Newman - January: {num_communities_january_gn} communities\")\n",
        "print(f\"Girvan-Newman - February: {num_communities_february_gn} communities\")\n",
        "print(f\"Girvan-Newman - March: {num_communities_march_gn} communities\")\n",
        "\n",
        "# זיהוי קהילות בכל חודש לפי Louvain\n",
        "communities_january_louvain = detect_louvain_communities(graph_january)\n",
        "communities_february_louvain = detect_louvain_communities(graph_february)\n",
        "communities_march_louvain = detect_louvain_communities(graph_march)\n",
        "\n",
        "num_communities_january_louvain = len(communities_january_louvain)\n",
        "num_communities_february_louvain = len(communities_february_louvain)\n",
        "num_communities_march_louvain = len(communities_march_louvain)\n",
        "\n",
        "print(f\"Louvain - January: {num_communities_january_louvain} communities\")\n",
        "print(f\"Louvain - February: {num_communities_february_louvain} communities\")\n",
        "print(f\"Louvain - March: {num_communities_march_louvain} communities\")\n",
        "\n",
        "# פונקציה לויזואליזציה של הקהילות\n",
        "def plot_communities(graph, communities, title):\n",
        "    pos = nx.spring_layout(graph)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # יצירת מחזור צבעים\n",
        "    colors = cycle(['r', 'g', 'b', 'c', 'm', 'y', 'k'])\n",
        "\n",
        "    for community in communities:\n",
        "        color = next(colors)\n",
        "        nx.draw_networkx_nodes(graph, pos, nodelist=community, node_size=50, node_color=color)\n",
        "    nx.draw_networkx_edges(graph, pos, alpha=0.5)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# ויזואליזציה של הקהילות\n",
        "plot_communities(graph_january, communities_january_gn, 'Communities in January (Girvan-Newman)')\n",
        "plot_communities(graph_february, communities_february_gn, 'Communities in February (Girvan-Newman)')\n",
        "plot_communities(graph_march, communities_march_gn, 'Communities in March (Girvan-Newman)')\n",
        "\n",
        "plot_communities(graph_january, communities_january_louvain, 'Communities in January (Louvain)')\n",
        "plot_communities(graph_february, communities_february_louvain, 'Communities in February (Louvain)')\n",
        "plot_communities(graph_march, communities_march_louvain, 'Communities in March (Louvain)')"
      ],
      "metadata": {
        "id": "fqfT_0m1qpLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "H3"
      ],
      "metadata": {
        "id": "583tWU-gqryQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# קריאת הקובץ עם טיפול בערכים מעורבים\n",
        "file_path = 'flights_cleaned.csv'  # ודא שהשם של הקובץ נכון\n",
        "data = pd.read_csv(file_path, dtype={'ORIGIN_AIRPORT': str, 'DESTINATION_AIRPORT': str}, low_memory=False)\n",
        "\n",
        "# יצירת גרף מכוון מהנתונים\n",
        "def create_directed_graph(data):\n",
        "    G = nx.DiGraph()\n",
        "    for index, row in data.iterrows():\n",
        "        G.add_edge(row['ORIGIN_AIRPORT'], row['DESTINATION_AIRPORT'])\n",
        "    return G\n",
        "\n",
        "graph = create_directed_graph(data)\n",
        "\n",
        "# חישוב Closeness Centrality\n",
        "closeness = nx.closeness_centrality(graph)\n",
        "\n",
        "# יצירת DataFrame עבור מדדי המרכזיות\n",
        "centrality_df = pd.DataFrame(list(closeness.items()), columns=['Airport', 'Closeness_Centrality'])\n",
        "\n",
        "# חישוב מספר הטיסות לכל נמל תעופה\n",
        "origin_counts = data['ORIGIN_AIRPORT'].value_counts()\n",
        "destination_counts = data['DESTINATION_AIRPORT'].value_counts()\n",
        "total_counts = origin_counts.add(destination_counts, fill_value=0).reset_index()\n",
        "total_counts.columns = ['Airport', 'Total_Flights']\n",
        "\n",
        "# מיזוג הנתונים\n",
        "merged_data = pd.merge(centrality_df, total_counts, on='Airport')\n",
        "\n",
        "# גרף פיזור (scatter plot) של Closeness Centrality לפי מספר הטיסות\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(x='Closeness_Centrality', y='Total_Flights', data=merged_data)\n",
        "plt.title('Closeness Centrality vs Total Flights')\n",
        "plt.xlabel('Closeness Centrality')\n",
        "plt.ylabel('Total Flights')\n",
        "plt.show()\n",
        "\n",
        "# חישוב הקורלציה\n",
        "correlation = merged_data['Closeness_Centrality'].corr(merged_data['Total_Flights'])\n",
        "print(f'Correlation between Closeness Centrality and Total Flights: {correlation}')"
      ],
      "metadata": {
        "id": "mkbzhOIcqtLL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}