{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD8QV0w6prNs"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.4' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "# File ID from Google Drive\n",
        "file_id = '1BX8Uce2Kj9sFNvyQaoKjoHClW-fK0VOn'\n",
        "\n",
        "# Construct the Google Drive download URL\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "# Local path to save the file\n",
        "destination = 'flights.csv'\n",
        "\n",
        "# Download the file\n",
        "print(\"Downloading file from Google Drive...\")\n",
        "gdown.download(url, destination, quiet=False)\n",
        "print(\"Download complete.\")\n",
        "\n",
        "# Check if file exists and has content\n",
        "if os.path.exists(destination) and os.path.getsize(destination) > 0:\n",
        "    # Read the CSV file\n",
        "    try:\n",
        "        data = pd.read_csv(destination, dtype={'ORIGIN_AIRPORT': str, 'DESTINATION_AIRPORT': str}, low_memory=False)\n",
        "        print(data.head())  # Display the first few rows to verify\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading the file: {str(e)}\")\n",
        "else:\n",
        "    print(\"File download failed or file is empty.\")\n",
        "    exit()\n",
        "\n",
        "# Check missing values in all columns\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Missing values in each column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Print the number of rows and columns\n",
        "num_rows, num_columns = data.shape\n",
        "print(f\"\\nNumber of rows: {num_rows}\")\n",
        "print(f\"Number of columns: {num_columns}\")\n",
        "\n",
        "# Keep only relevant columns\n",
        "columns_to_keep = [\n",
        "    'YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE', 'FLIGHT_NUMBER',\n",
        "    'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
        "    'DEPARTURE_TIME', 'DEPARTURE_DELAY'\n",
        "]\n",
        "data = data[columns_to_keep]\n",
        "\n",
        "# Remove rows with NaNs in required columns\n",
        "data_cleaned = data.dropna(subset=columns_to_keep)\n",
        "\n",
        "# Save the new file\n",
        "cleaned_file_path = 'flights_cleaned.csv'\n",
        "data_cleaned.to_csv(cleaned_file_path, index=False)\n",
        "\n",
        "print(f\"Data cleaned and saved to {cleaned_file_path}\")\n",
        "\n",
        "# Read the cleaned file\n",
        "data = pd.read_csv(cleaned_file_path, dtype={'ORIGIN_AIRPORT': str, 'DESTINATION_AIRPORT': str}, low_memory=False)\n",
        "\n",
        "# Check missing values in all columns again\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Missing values in each column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Print the number of rows and columns\n",
        "num_rows, num_columns = data.shape\n",
        "print(f\"\\nNumber of rows: {num_rows}\")\n",
        "print(f\"Number of columns: {num_columns}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O_k4mhbqfcN"
      },
      "source": [
        "hypothesisone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wlepa58RqPZK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# קריאת הקובץ עם טיפול בערכים מעורבים\n",
        "file_path = 'flights_cleaned.csv'  # ודא שהשם של הקובץ נכון\n",
        "data = pd.read_csv(file_path, dtype={'ORIGIN_AIRPORT': str, 'DESTINATION_AIRPORT': str}, low_memory=False)\n",
        "\n",
        "# יצירת גרף מכוון מהנתונים\n",
        "def create_directed_graph(data):\n",
        "    G = nx.DiGraph()\n",
        "    for index, row in data.iterrows():\n",
        "        G.add_edge(row['ORIGIN_AIRPORT'], row['DESTINATION_AIRPORT'])\n",
        "    return G\n",
        "\n",
        "graph = create_directed_graph(data)\n",
        "\n",
        "# חישוב Betweenness Centrality\n",
        "betweenness = nx.betweenness_centrality(graph)\n",
        "\n",
        "# יצירת DataFrame עבור מדדי המרכזיות\n",
        "centrality_df = pd.DataFrame(list(betweenness.items()), columns=['Airport', 'Betweenness_Centrality'])\n",
        "\n",
        "# חישוב עיכובים ממוצעים לכל נמל תעופה\n",
        "delay_data = data.groupby('ORIGIN_AIRPORT')['DEPARTURE_DELAY'].mean().reset_index()\n",
        "delay_data.columns = ['Airport', 'Average_Departure_Delay']\n",
        "\n",
        "# מיזוג הנתונים\n",
        "merged_data = pd.merge(centrality_df, delay_data, on='Airport')\n",
        "\n",
        "# הדפסת התוצאות\n",
        "print(merged_data)\n",
        "\n",
        "# יצירת גרף להשוואת מדדי המרכזיות לעיכובים הממוצעים\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Betweenness_Centrality', y='Average_Departure_Delay', data=merged_data)\n",
        "plt.xlabel('Betweenness Centrality')\n",
        "plt.ylabel('Average Departure Delay')\n",
        "plt.title('Betweenness Centrality vs. Average Departure Delay')\n",
        "plt.show()\n",
        "\n",
        "# חישוב הקורלציה\n",
        "correlation = merged_data['Betweenness_Centrality'].corr(merged_data['Average_Departure_Delay'])\n",
        "print(f'Correlation between Betweenness Centrality and Average Departure Delay: {correlation}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KmLvNQYqoAN"
      },
      "source": [
        "H2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqfT_0m1qpLD"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "from networkx.algorithms.community import girvan_newman\n",
        "import community.community_louvain as community_louvain\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "\n",
        "# פונקציה לחלוקת הגרף לקהילות לפי אלגוריתם Girvan-Newman\n",
        "def detect_girvan_newman_communities(graph):\n",
        "    comp = girvan_newman(graph)\n",
        "    return next(comp)\n",
        "\n",
        "# פונקציה לחלוקת הגרף לקהילות לפי אלגוריתם Louvain\n",
        "def detect_louvain_communities(graph):\n",
        "    partition = community_louvain.best_partition(graph)\n",
        "    communities = {}\n",
        "    for node, community in partition.items():\n",
        "        if community not in communities:\n",
        "            communities[community] = []\n",
        "        communities[community].append(node)\n",
        "    return list(communities.values())\n",
        "\n",
        "# יצירת גרפים עבור כל חודש\n",
        "def create_graph(data):\n",
        "    G = nx.Graph()\n",
        "    for index, row in data.iterrows():\n",
        "        G.add_edge(row['ORIGIN_AIRPORT'], row['DESTINATION_AIRPORT'])\n",
        "    return G\n",
        "\n",
        "# קריאת הקובץ\n",
        "file_path = 'flights_cleaned.csv'\n",
        "data = pd.read_csv(file_path, dtype={'ORIGIN_AIRPORT': str, 'DESTINATION_AIRPORT': str}, low_memory=False)\n",
        "\n",
        "data_january = data[data['MONTH'] == 1]\n",
        "data_february = data[data['MONTH'] == 2]\n",
        "data_march = data[data['MONTH'] == 3]\n",
        "\n",
        "graph_january = create_graph(data_january)\n",
        "graph_february = create_graph(data_february)\n",
        "graph_march = create_graph(data_march)\n",
        "\n",
        "# בדיקת מספר הצמתים והקשתות בכל חודש\n",
        "print(f\"January: {graph_january.number_of_nodes()} nodes, {graph_january.number_of_edges()} edges\")\n",
        "print(f\"February: {graph_february.number_of_nodes()} nodes, {graph_february.number_of_edges()} edges\")\n",
        "print(f\"March: {graph_march.number_of_nodes()} nodes, {graph_march.number_of_edges()} edges\")\n",
        "\n",
        "# זיהוי קהילות בכל חודש לפי Girvan-Newman\n",
        "communities_january_gn = detect_girvan_newman_communities(graph_january)\n",
        "communities_february_gn = detect_girvan_newman_communities(graph_february)\n",
        "communities_march_gn = detect_girvan_newman_communities(graph_march)\n",
        "\n",
        "num_communities_january_gn = len(list(communities_january_gn))\n",
        "num_communities_february_gn = len(list(communities_february_gn))\n",
        "num_communities_march_gn = len(list(communities_march_gn))\n",
        "\n",
        "print(f\"Girvan-Newman - January: {num_communities_january_gn} communities\")\n",
        "print(f\"Girvan-Newman - February: {num_communities_february_gn} communities\")\n",
        "print(f\"Girvan-Newman - March: {num_communities_march_gn} communities\")\n",
        "\n",
        "# זיהוי קהילות בכל חודש לפי Louvain\n",
        "communities_january_louvain = detect_louvain_communities(graph_january)\n",
        "communities_february_louvain = detect_louvain_communities(graph_february)\n",
        "communities_march_louvain = detect_louvain_communities(graph_march)\n",
        "\n",
        "num_communities_january_louvain = len(communities_january_louvain)\n",
        "num_communities_february_louvain = len(communities_february_louvain)\n",
        "num_communities_march_louvain = len(communities_march_louvain)\n",
        "\n",
        "print(f\"Louvain - January: {num_communities_january_louvain} communities\")\n",
        "print(f\"Louvain - February: {num_communities_february_louvain} communities\")\n",
        "print(f\"Louvain - March: {num_communities_march_louvain} communities\")\n",
        "\n",
        "# פונקציה לויזואליזציה של הקהילות\n",
        "def plot_communities(graph, communities, title):\n",
        "    pos = nx.spring_layout(graph)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # יצירת מחזור צבעים\n",
        "    colors = cycle(['r', 'g', 'b', 'c', 'm', 'y', 'k'])\n",
        "\n",
        "    for community in communities:\n",
        "        color = next(colors)\n",
        "        nx.draw_networkx_nodes(graph, pos, nodelist=community, node_size=50, node_color=color)\n",
        "    nx.draw_networkx_edges(graph, pos, alpha=0.5)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# ויזואליזציה של הקהילות\n",
        "plot_communities(graph_january, communities_january_gn, 'Communities in January (Girvan-Newman)')\n",
        "plot_communities(graph_february, communities_february_gn, 'Communities in February (Girvan-Newman)')\n",
        "plot_communities(graph_march, communities_march_gn, 'Communities in March (Girvan-Newman)')\n",
        "\n",
        "plot_communities(graph_january, communities_january_louvain, 'Communities in January (Louvain)')\n",
        "plot_communities(graph_february, communities_february_louvain, 'Communities in February (Louvain)')\n",
        "plot_communities(graph_march, communities_march_louvain, 'Communities in March (Louvain)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "583tWU-gqryQ"
      },
      "source": [
        "H3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkbzhOIcqtLL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# קריאת הקובץ עם טיפול בערכים מעורבים\n",
        "file_path = 'flights_cleaned.csv'  # ודא שהשם של הקובץ נכון\n",
        "data = pd.read_csv(file_path, dtype={'ORIGIN_AIRPORT': str, 'DESTINATION_AIRPORT': str}, low_memory=False)\n",
        "\n",
        "# יצירת גרף מכוון מהנתונים\n",
        "def create_directed_graph(data):\n",
        "    G = nx.DiGraph()\n",
        "    for index, row in data.iterrows():\n",
        "        G.add_edge(row['ORIGIN_AIRPORT'], row['DESTINATION_AIRPORT'])\n",
        "    return G\n",
        "\n",
        "graph = create_directed_graph(data)\n",
        "\n",
        "# חישוב Closeness Centrality\n",
        "closeness = nx.closeness_centrality(graph)\n",
        "\n",
        "# יצירת DataFrame עבור מדדי המרכזיות\n",
        "centrality_df = pd.DataFrame(list(closeness.items()), columns=['Airport', 'Closeness_Centrality'])\n",
        "\n",
        "# חישוב מספר הטיסות לכל נמל תעופה\n",
        "origin_counts = data['ORIGIN_AIRPORT'].value_counts()\n",
        "destination_counts = data['DESTINATION_AIRPORT'].value_counts()\n",
        "total_counts = origin_counts.add(destination_counts, fill_value=0).reset_index()\n",
        "total_counts.columns = ['Airport', 'Total_Flights']\n",
        "\n",
        "# מיזוג הנתונים\n",
        "merged_data = pd.merge(centrality_df, total_counts, on='Airport')\n",
        "\n",
        "# גרף פיזור (scatter plot) של Closeness Centrality לפי מספר הטיסות\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(x='Closeness_Centrality', y='Total_Flights', data=merged_data)\n",
        "plt.title('Closeness Centrality vs Total Flights')\n",
        "plt.xlabel('Closeness Centrality')\n",
        "plt.ylabel('Total Flights')\n",
        "plt.show()\n",
        "\n",
        "# חישוב הקורלציה\n",
        "correlation = merged_data['Closeness_Centrality'].corr(merged_data['Total_Flights'])\n",
        "print(f'Correlation between Closeness Centrality and Total Flights: {correlation}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
